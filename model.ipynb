{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for the ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:45:02.223477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WVHT       SwH       SwP       WWH       WWP     SwD   WWD  Steepness  \\\n",
      "0  0.461538  0.621622  0.679389  0.142857  0.177419  0.4375  0.00   0.666667   \n",
      "1  0.615385  0.729730  0.679389  0.178571  0.209677  0.8750  0.00   0.666667   \n",
      "2  0.538462  0.675676  0.603053  0.178571  0.338710  0.8750  0.25   0.666667   \n",
      "3  0.538462  0.675676  0.679389  0.142857  0.209677  0.8750  0.00   0.666667   \n",
      "4  0.769231  0.837838  0.679389  0.142857  0.225806  0.4375  0.00   0.666667   \n",
      "\n",
      "        APD       MWD  ...      WSPD       GST       DPD      PRES      ATMP  \\\n",
      "0  0.517241  0.871866  ...  0.416667  0.428571  0.692308  0.420168  0.804878   \n",
      "1  0.655172  0.832869  ...  0.500000  0.428571  0.666667  0.411765  0.780488   \n",
      "2  0.586207  0.832869  ...  0.500000  0.500000  0.641026  0.436975  0.780488   \n",
      "3  0.603448  0.832869  ...  0.416667  0.428571  0.692308  0.453782  0.756098   \n",
      "4  0.844828  0.860724  ...  0.500000  0.428571  0.692308  0.478992  0.780488   \n",
      "\n",
      "       WTMP  month_sin  month_cos   day_sin  day_cos  \n",
      "0  0.142857        1.0        1.0  1.000000  1.00000  \n",
      "1  0.214286        1.0        1.0  1.000000  1.00000  \n",
      "2  0.214286        1.0        1.0  1.000000  1.00000  \n",
      "3  0.214286        1.0        1.0  1.000000  1.00000  \n",
      "4  0.214286        1.0        1.0  0.945696  0.98677  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(3160, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "buoy_data = pd.read_csv('buoyData_11-3-24.csv')\n",
    "\n",
    "# Convert `datetime` column to datetime format\n",
    "buoy_data['datetime'] = pd.to_datetime(buoy_data['datetime'])\n",
    "\n",
    "# Interpolate missing numeric values\n",
    "numeric_columns = buoy_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "buoy_data[numeric_columns] = buoy_data[numeric_columns].interpolate()\n",
    "\n",
    "# Drop column with all missing values\n",
    "buoy_data = buoy_data.drop(['DEWP'], axis=1)\n",
    "\n",
    "# Encode categorical columns using LabelEncoder\n",
    "categorical_columns = ['SwD', 'WWD', 'Steepness']\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    buoy_data[col] = le.fit_transform(buoy_data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Extract time-of-year features and apply sine/cosine transformations\n",
    "buoy_data['month'] = buoy_data['datetime'].dt.month\n",
    "buoy_data['day_of_year'] = buoy_data['datetime'].dt.dayofyear\n",
    "\n",
    "# Sine/Cosine transformations for cyclical encoding\n",
    "buoy_data['month_sin'] = np.sin(2 * np.pi * buoy_data['month'] / 12)\n",
    "buoy_data['month_cos'] = np.cos(2 * np.pi * buoy_data['month'] / 12)\n",
    "buoy_data['day_sin'] = np.sin(2 * np.pi * buoy_data['day_of_year'] / 365)\n",
    "buoy_data['day_cos'] = np.cos(2 * np.pi * buoy_data['day_of_year'] / 365)\n",
    "\n",
    "# Drop columns that are not needed anymore\n",
    "buoy_data = buoy_data.drop(['datetime', 'month', 'day_of_year'], axis=1)\n",
    "\n",
    "# Normalize all numeric features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "numeric_features = buoy_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "buoy_data[numeric_features] = scaler.fit_transform(buoy_data[numeric_features])\n",
    "\n",
    "\n",
    "#Uncomment below to see the data sent to the model in a csv\n",
    "#buoy_data.to_csv('processed_buoy_data.csv', index=False)\n",
    "\n",
    "print(buoy_data.head())\n",
    "print(buoy_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define feature columns \n",
    "feature_columns = buoy_data.columns.drop('WVHT')\n",
    "\n",
    "# 2. Scale data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(buoy_data[feature_columns])\n",
    "\n",
    "# 3. Prepare Sequences for Training\n",
    "\n",
    "sequence_length = 48  #Need to adjust this\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, target, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(target[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_data, buoy_data['WVHT'].values, sequence_length)\n",
    "\n",
    "# Split data into train and test sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# 4. Build the LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# 5. Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# 6. Evaluate the Model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transit time and transformations\n",
    "# Calculate transit time and adjusted wave height at Pipeline\n",
    "#buoy_data['transit_time'] = buoy_data['SwP'].apply(transformations.calculate_transit_time)\n",
    "#buoy_data['pipeline_wave_height'] = transformations.predict_pipeline_wave_height_vectorized(buoy_data['WVHT'], buoy_data['SwP'], buoy_data['SwD'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8278334bc8d564ed99282a103aba0b0ee2c694fbe3545395931ebbbcbdbf1825"
  },
  "kernelspec": {
   "display_name": "Python 3.12.7 ('surf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
